{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataloader_image_classification import ImageTransform, make_datapath_list, HymenopteraDataset\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/hymenoptera_data/train/**/*.jpg\n",
      "./data/hymenoptera_data/val/**/*.jpg\n"
     ]
    }
   ],
   "source": [
    "#get datapath list\n",
    "train_list = make_datapath_list(phase=\"train\")\n",
    "val_list = make_datapath_list(phase=\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 224\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "train_dataset = HymenopteraDataset(\n",
    "    file_list=train_list, transform=ImageTransform(size, mean, std), phase=\"train\"\n",
    ")\n",
    "val_dataset = HymenopteraDataset(\n",
    "    file_list=val_list, transform=ImageTransform(size, mean, std), phase=\"val\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset by batch\n",
    "batch_size = 32\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders_dict = {\n",
    "    \"train\": train_dataloader,\n",
    "    \"val\": val_dataloader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.weight\n",
      "features.0.bias\n",
      "features.2.weight\n",
      "features.2.bias\n",
      "features.5.weight\n",
      "features.5.bias\n",
      "features.7.weight\n",
      "features.7.bias\n",
      "features.10.weight\n",
      "features.10.bias\n",
      "features.12.weight\n",
      "features.12.bias\n",
      "features.14.weight\n",
      "features.14.bias\n",
      "features.17.weight\n",
      "features.17.bias\n",
      "features.19.weight\n",
      "features.19.bias\n",
      "features.21.weight\n",
      "features.21.bias\n",
      "features.24.weight\n",
      "features.24.bias\n",
      "features.26.weight\n",
      "features.26.bias\n",
      "features.28.weight\n",
      "features.28.bias\n",
      "classifier.0.weight\n",
      "classifier.0.bias\n",
      "classifier.3.weight\n",
      "classifier.3.bias\n",
      "classifier.6.weight\n",
      "classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "use_pretrained = torchvision.models.VGG16_Weights.DEFAULT\n",
    "net = models.vgg16(weights=use_pretrained)\n",
    "\n",
    "net.classifier[6] = nn.Linear(in_features=4096, out_features=2)\n",
    "net.train()\n",
    "\n",
    "for name, _ in net.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.weight updated in param 1\n",
      "features.0.bias updated in param 1\n",
      "features.2.weight updated in param 1\n",
      "features.2.bias updated in param 1\n",
      "features.5.weight updated in param 1\n",
      "features.5.bias updated in param 1\n",
      "features.7.weight updated in param 1\n",
      "features.7.bias updated in param 1\n",
      "features.10.weight updated in param 1\n",
      "features.10.bias updated in param 1\n",
      "features.12.weight updated in param 1\n",
      "features.12.bias updated in param 1\n",
      "features.14.weight updated in param 1\n",
      "features.14.bias updated in param 1\n",
      "features.17.weight updated in param 1\n",
      "features.17.bias updated in param 1\n",
      "features.19.weight updated in param 1\n",
      "features.19.bias updated in param 1\n",
      "features.21.weight updated in param 1\n",
      "features.21.bias updated in param 1\n",
      "features.24.weight updated in param 1\n",
      "features.24.bias updated in param 1\n",
      "features.26.weight updated in param 1\n",
      "features.26.bias updated in param 1\n",
      "features.28.weight updated in param 1\n",
      "features.28.bias updated in param 1\n",
      "classifier.0.weight updated in param 2\n",
      "classifier.0.bias updated in param 2\n",
      "classifier.3.weight updated in param 2\n",
      "classifier.3.bias updated in param 2\n",
      "classifier.6.weight updated in param 3\n",
      "classifier.6.bias updated in param 3\n"
     ]
    }
   ],
   "source": [
    "#fine tuning the model\n",
    "params_to_update1, params_to_update2, params_to_update3 = [], [], []\n",
    "update_list1 = [\n",
    "    \"classifier.0.weight\", \"classifier.0.bias\", \"classifier.3.weight\", \"classifier.3.bias\"\n",
    "]\n",
    "update_list2 = [\n",
    "    \"classifier.6.weight\", \"classifier.6.bias\"\n",
    "]\n",
    "\n",
    "for name, param in net.named_parameters():\n",
    "    #update feature layer\n",
    "    if \"features\" in name:\n",
    "        param.requires_grad = True\n",
    "        params_to_update1.append(param)\n",
    "        print(f\"{name} updated in param 1\")\n",
    "    elif name in update_list1:\n",
    "        param.requires_grad = True\n",
    "        params_to_update2.append(param)\n",
    "        print(f\"{name} updated in param 2\")\n",
    "    elif name in update_list2:\n",
    "        param.requires_grad = True\n",
    "        params_to_update3.append(param)\n",
    "        print(f\"{name} updated in param 3\")\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "        print(f\"{name} not update when train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD([\n",
    "    {\"params\": params_to_update1, \"lr\": 1e-4},\n",
    "    {\"params\": params_to_update2, \"lr\": 5e-4},\n",
    "    {\"params\": params_to_update3, \"lr\": 1e-3},\n",
    "], momentum=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    "    device = torch.device('mps:0' if torch.backends.mps.is_available() else 'cpu')\n",
    "    print(f\"Device:{device}\")\n",
    "\n",
    "    net.to(device)\n",
    "\n",
    "    #automatically choose best convolution algorithm\n",
    "    #if input size == static, this will work\n",
    "    #else may slow down\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch: {epoch+1}/{num_epochs}\", end=\"\\n====================\\n\")\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                net.train()\n",
    "            else:\n",
    "                net.eval()\n",
    "\n",
    "            epoch_loss = 0.0\n",
    "            epoch_corrects = 0\n",
    "\n",
    "            for inputs, labels in tqdm(dataloaders_dict[phase], colour=\"green\"):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase==\"train\"):\n",
    "                    outputs = net(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    preds = outputs.argmax(1)\n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    epoch_loss += loss.item() * inputs.size(0)\n",
    "                    epoch_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            print(f\"{phase} Loss: {epoch_loss/len(dataloaders_dict[phase].dataset):.4f} Acc: {epoch_corrects.double()/len(dataloaders_dict[phase].dataset):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:mps:0\n",
      "Epoch: 1/5\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m██████████\u001b[0m| 8/8 [00:16<00:00,  2.12s/it]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m num_epochs \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[0;32m----> 2\u001b[0m train(net, dataloaders_dict, criterion, optimizer, num_epochs\u001b[39m=\u001b[39;49mnum_epochs)\n",
      "Cell \u001b[0;32mIn[25], line 41\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(net, dataloaders_dict, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     38\u001b[0m         epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem() \u001b[39m*\u001b[39m inputs\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[1;32m     39\u001b[0m         epoch_corrects \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum(preds \u001b[39m==\u001b[39m labels\u001b[39m.\u001b[39mdata)\n\u001b[0;32m---> 41\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mphase\u001b[39m}\u001b[39;00m\u001b[39m Loss: \u001b[39m\u001b[39m{\u001b[39;00mepoch_loss\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(dataloaders_dict[phase]\u001b[39m.\u001b[39mdataset)\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m Acc: \u001b[39m\u001b[39m{\u001b[39;00mepoch_corrects\u001b[39m.\u001b[39;49mdouble()\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(dataloaders_dict[phase]\u001b[39m.\u001b[39mdataset)\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead."
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "train(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
