{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import random\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datapath_list(rootpath):\n",
    "    imgpath_template = osp.join(rootpath, \"JPEGImages\", \"%s.jpg\")\n",
    "    annopath_template = osp.join(rootpath, \"Annotations\", \"%s.xml\")\n",
    "\n",
    "    train_id_names = osp.join(rootpath + \"ImageSets/Main/train.txt\")\n",
    "    val_id_names = osp.join(rootpath + \"ImageSets/Main/val.txt\")\n",
    "    \n",
    "    train_img_list = list()\n",
    "    train_anno_list = list()\n",
    "\n",
    "    for line in open(train_id_names):\n",
    "        file_id = line.strip()\n",
    "        img_path = (imgpath_template % file_id)\n",
    "        anno_path = (annopath_template % file_id)\n",
    "        train_img_list.append(img_path)\n",
    "        train_anno_list.append(anno_path)\n",
    "\n",
    "    val_img_list = list()\n",
    "    val_anno_list = list()\n",
    "\n",
    "    for line in open(val_id_names):\n",
    "        file_id = line.strip()\n",
    "        img_path = (imgpath_template % file_id)\n",
    "        anno_path = (annopath_template % file_id)\n",
    "        val_img_list.append(img_path)\n",
    "        val_anno_list.append(anno_path)\n",
    "\n",
    "    return train_img_list, train_anno_list, val_img_list, val_anno_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/VOCdevkit/VOC2012/JPEGImages/2008_000008.jpg\n"
     ]
    }
   ],
   "source": [
    "rootpath = \"./data/VOCdevkit/VOC2012/\"\n",
    "\n",
    "train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(rootpath)\n",
    "\n",
    "print(train_img_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nANNOTATION.xml sample format\\n\\n<annotation>\\n\\t<folder>VOC2012</folder>\\n\\t<filename>2007_000027.jpg</filename>\\n\\t<source>\\n\\t\\t<database>The VOC2007 Database</database>\\n\\t\\t<annotation>PASCAL VOC2007</annotation>\\n\\t\\t<image>flickr</image>\\n\\t</source>\\n\\t<size>\\n\\t\\t<width>486</width>\\n\\t\\t<height>500</height>\\n\\t\\t<depth>3</depth>\\n\\t</size>\\n\\t<segmented>0</segmented>\\n\\t<object>\\n\\t\\t<name>person</name>\\n\\t\\t<pose>Unspecified</pose>\\n\\t\\t<truncated>0</truncated>\\n\\t\\t<difficult>0</difficult>\\n\\t\\t<bndbox>\\n\\t\\t\\t<xmin>174</xmin>\\n\\t\\t\\t<ymin>101</ymin>\\n\\t\\t\\t<xmax>349</xmax>\\n\\t\\t\\t<ymax>351</ymax>\\n\\t\\t</bndbox>\\n\\t\\t<part>\\n\\t\\t\\t<name>head</name>\\n\\t\\t\\t<bndbox>\\n\\t\\t\\t\\t<xmin>169</xmin>\\n\\t\\t\\t\\t<ymin>104</ymin>\\n\\t\\t\\t\\t<xmax>209</xmax>\\n\\t\\t\\t\\t<ymax>146</ymax>\\n\\t\\t\\t</bndbox>\\n\\t\\t</part>\\n\\t\\t<part>\\n\\t\\t\\t<name>hand</name>\\n\\t\\t\\t<bndbox>\\n\\t\\t\\t\\t<xmin>278</xmin>\\n\\t\\t\\t\\t<ymin>210</ymin>\\n\\t\\t\\t\\t<xmax>297</xmax>\\n\\t\\t\\t\\t<ymax>233</ymax>\\n\\t\\t\\t</bndbox>\\n\\t\\t</part>\\n\\t\\t<part>\\n\\t\\t\\t<name>foot</name>\\n\\t\\t\\t<bndbox>\\n\\t\\t\\t\\t<xmin>273</xmin>\\n\\t\\t\\t\\t<ymin>333</ymin>\\n\\t\\t\\t\\t<xmax>297</xmax>\\n\\t\\t\\t\\t<ymax>354</ymax>\\n\\t\\t\\t</bndbox>\\n\\t\\t</part>\\n\\t\\t<part>\\n\\t\\t\\t<name>foot</name>\\n\\t\\t\\t<bndbox>\\n\\t\\t\\t\\t<xmin>319</xmin>\\n\\t\\t\\t\\t<ymin>307</ymin>\\n\\t\\t\\t\\t<xmax>340</xmax>\\n\\t\\t\\t\\t<ymax>326</ymax>\\n\\t\\t\\t</bndbox>\\n\\t\\t</part>\\n\\t</object>\\n</annotation>\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "ANNOTATION.xml sample format\n",
    "\n",
    "<annotation>\n",
    "\t<folder>VOC2012</folder>\n",
    "\t<filename>2007_000027.jpg</filename>\n",
    "\t<source>\n",
    "\t\t<database>The VOC2007 Database</database>\n",
    "\t\t<annotation>PASCAL VOC2007</annotation>\n",
    "\t\t<image>flickr</image>\n",
    "\t</source>\n",
    "\t<size>\n",
    "\t\t<width>486</width>\n",
    "\t\t<height>500</height>\n",
    "\t\t<depth>3</depth>\n",
    "\t</size>\n",
    "\t<segmented>0</segmented>\n",
    "\t<object>\n",
    "\t\t<name>person</name>\n",
    "\t\t<pose>Unspecified</pose>\n",
    "\t\t<truncated>0</truncated>\n",
    "\t\t<difficult>0</difficult>\n",
    "\t\t<bndbox>\n",
    "\t\t\t<xmin>174</xmin>\n",
    "\t\t\t<ymin>101</ymin>\n",
    "\t\t\t<xmax>349</xmax>\n",
    "\t\t\t<ymax>351</ymax>\n",
    "\t\t</bndbox>\n",
    "\t\t<part>\n",
    "\t\t\t<name>head</name>\n",
    "\t\t\t<bndbox>\n",
    "\t\t\t\t<xmin>169</xmin>\n",
    "\t\t\t\t<ymin>104</ymin>\n",
    "\t\t\t\t<xmax>209</xmax>\n",
    "\t\t\t\t<ymax>146</ymax>\n",
    "\t\t\t</bndbox>\n",
    "\t\t</part>\n",
    "\t\t<part>\n",
    "\t\t\t<name>hand</name>\n",
    "\t\t\t<bndbox>\n",
    "\t\t\t\t<xmin>278</xmin>\n",
    "\t\t\t\t<ymin>210</ymin>\n",
    "\t\t\t\t<xmax>297</xmax>\n",
    "\t\t\t\t<ymax>233</ymax>\n",
    "\t\t\t</bndbox>\n",
    "\t\t</part>\n",
    "\t\t<part>\n",
    "\t\t\t<name>foot</name>\n",
    "\t\t\t<bndbox>\n",
    "\t\t\t\t<xmin>273</xmin>\n",
    "\t\t\t\t<ymin>333</ymin>\n",
    "\t\t\t\t<xmax>297</xmax>\n",
    "\t\t\t\t<ymax>354</ymax>\n",
    "\t\t\t</bndbox>\n",
    "\t\t</part>\n",
    "\t\t<part>\n",
    "\t\t\t<name>foot</name>\n",
    "\t\t\t<bndbox>\n",
    "\t\t\t\t<xmin>319</xmin>\n",
    "\t\t\t\t<ymin>307</ymin>\n",
    "\t\t\t\t<xmax>340</xmax>\n",
    "\t\t\t\t<ymax>326</ymax>\n",
    "\t\t\t</bndbox>\n",
    "\t\t</part>\n",
    "\t</object>\n",
    "</annotation>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Anno_xml2list():\n",
    "    def __init__(self, classes):\n",
    "        self.classes = classes\n",
    "\n",
    "    def __call__(self, xml_path, width, height):\n",
    "        \"\"\"\n",
    "        in:\n",
    "            xml_path: str, xml 파일경로\n",
    "            width, height: int\n",
    "            ret:[[xmin, ymin, xmax, ymax, label_idx], ...], Annotation Data List\n",
    "        \"\"\"\n",
    "        #모든 물체의 annotation 저장\n",
    "        ret = []\n",
    "\n",
    "        xml = ET.parse(xml_path).getroot()\n",
    "\n",
    "        #물체 개수(object) iterate\n",
    "        for obj in xml.iter(\"object\"):\n",
    "            name = \"\"\n",
    "            difficult = int(obj.find(\"difficult\").text)\n",
    "            if difficult == 1:\n",
    "                continue\n",
    "            \n",
    "            #bounding box for each object\n",
    "            bndbox = []\n",
    "            name = obj.find(\"name\").text.lower().strip() #공백제거\n",
    "            bbox = obj.find(\"bndbox\")\n",
    "\n",
    "            pts = [\"xmin\", \"ymin\", \"xmax\", \"ymax\"]\n",
    "            for pt in pts:\n",
    "                cur_pixel = int(bbox.find(pt).text) - 1\n",
    "                #Normalize\n",
    "                if pt == \"xmin\" or pt == \"xmax\":\n",
    "                    cur_pixel /= width\n",
    "                else:\n",
    "                    cur_pixel /= height\n",
    "\n",
    "                bndbox.append(cur_pixel)\n",
    "\n",
    "            label_idx = self.classes.index(name)\n",
    "            bndbox.append(label_idx)\n",
    "            ret.append(bndbox)\n",
    "        print(f\"{xml_path}\")\n",
    "        return np.array(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/VOCdevkit/VOC2012/Annotations/2008_000115.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.216 , 0.325 , 0.92  , 0.735 , 7.    ],\n",
       "       [0.    , 0.    , 0.992 , 0.9975, 8.    ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc_classes = [\n",
    "    \"aeroplane\",\n",
    "    \"bicycle\",\n",
    "    \"bird\",\n",
    "    \"boat\",\n",
    "    \"bottle\",\n",
    "    \"bus\",\n",
    "    \"car\",\n",
    "    \"cat\",\n",
    "    \"chair\",\n",
    "    \"cow\",\n",
    "    \"diningtable\",\n",
    "    \"dog\",\n",
    "    \"horse\",\n",
    "    \"motorbike\",\n",
    "    \"person\",\n",
    "    \"pottedplant\",\n",
    "    \"sheep\",\n",
    "    \"sofa\",\n",
    "    \"train\",\n",
    "    \"tvmonitor\",\n",
    "]\n",
    "\n",
    "transform_anno = Anno_xml2list(voc_classes)\n",
    "\n",
    "ind = random.randint(0, 30)\n",
    "image_file_path = val_img_list[ind]\n",
    "img = cv2.imread(image_file_path)\n",
    "height, width, channels = img.shape\n",
    "\n",
    "transform_anno(val_anno_list[ind], width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
